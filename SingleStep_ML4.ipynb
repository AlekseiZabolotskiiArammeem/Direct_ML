{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89633203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import Merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Flatten\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers.merge import concatenate\n",
    "#import tensorflow as tf\n",
    "#import tensorflow_addons as tfa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99432a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('orders.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_orders = pd.read_csv('table_orders.csv')\n",
    "table_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_orders = table_orders.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e262eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = table_orders.iloc[0:1000,0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = pd.pivot_table(dataset, values='pred_orders', index=['time'],columns=['fid'])\n",
    "table2= table2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25775199",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = table2.sort_values(by = ['time'], ascending = [False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7864625",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2.to_csv('predicts00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede22778",
   "metadata": {},
   "outputs": [],
   "source": [
    "table4 = pd.pivot_table(dataset, values='orders', index=['time'],columns=['fid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table4 = table4.sort_values(by = ['time'], ascending = [False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b590277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data # data for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa747c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "table44 = pd.read_csv('predicts0044.csv') # for coMparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe866a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table44 = pd.read_csv('timedddd.csv')\n",
    "table44.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd = pd.read_csv('timedddd.csv',sep = ';') # turned into parallel hexagon array\n",
    "dddd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd = dddd.set_index('time')\n",
    "dddd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aceb0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd1 = dddd.iloc[0:1000,1:2]\n",
    "dddd1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeec6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd1 = np.asarray(dddd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042a405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f2360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "table4.to_csv('predicts0044.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d27956",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv('table_orders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('table_orders.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1698447",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542fb7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset\n",
    "data = data.iloc[0:1000,0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.shift(48, axis = 0) # Data shift - train X - shifted y 48 hours prediction fro shifted data X - y\n",
    "X_train  = X_train .fillna(0)\n",
    "y_train = data.shift(24, axis = 0)\n",
    "y_train = y_train.fillna(0)\n",
    "X_test = data.shift(24, axis = 0)\n",
    "X_test = X_test[0:48].fillna(0)\n",
    "X_train1 = np.asarray(X_train)\n",
    "y_train1 = np.asarray(y_train)\n",
    "X_test1 = np.asarray(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c2adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.shift(2, axis = 0)\n",
    "X_train  = X_train .fillna(0)\n",
    "y_train = data.shift(1, axis = 0)\n",
    "y_train = y_train.fillna(0)\n",
    "X_test = data.shift(1, axis = 0)\n",
    "X_test = X_test.fillna(0)\n",
    "X_train1 = np.asarray(X_train)\n",
    "y_train1 = np.asarray(y_train)\n",
    "X_test1 = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd = pd.read_csv('timedddd.csv',sep = ';') # turned into parallel hexagon array\n",
    "dddd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a18e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = table1.shift(24, axis = 0)\n",
    "table2 = table2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1650a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5f73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fa2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b15fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"System Version: {sys.version}\")\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (17, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "notebookstart= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992011f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table= table.fillna(0)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44e168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79bc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05d52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927953fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.to_scv('xgboostsingle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9f373",
   "metadata": {},
   "source": [
    "# Single Hexagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02832652",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a9ae9",
   "metadata": {},
   "source": [
    "# XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "# load the dataset\n",
    "series = dddd1#read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in=6)\n",
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 12)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600e0695",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d41dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with random forest\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = RandomForestRegressor(n_estimators=1000)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "# load the dataset\n",
    "series = dddd1#read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in=6)\n",
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 48)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f5ccb9",
   "metadata": {},
   "source": [
    "# AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3bdc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = AdaBoostRegressor(n_estimators=1000)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "# load the dataset\n",
    "series = dddd1#read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in=6)\n",
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 48)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c641795",
   "metadata": {},
   "source": [
    "# AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d8dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62962c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recursive multi-step forecast with linear algorithms\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1983d",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = Ridge(alpha=0.1)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "# load the dataset\n",
    "series = dddd1#read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in=1)\n",
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 48)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca78f73",
   "metadata": {},
   "source": [
    "# lgb.LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def LGBM(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = lgb.LGBMRegressor()\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = LGBM(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "# load the dataset\n",
    "series = dddd1#read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in=1)\n",
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 48)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95610f21",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea54592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = Ridge(alpha=0.1)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "# load the dataset\n",
    "series = dddd1#read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in=1)\n",
    "# evaluate\n",
    "mae, y, yhat = walk_forward_validation(data, 48)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "pyplot.plot(y, label='Expected')\n",
    "pyplot.plot(yhat, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9907c21",
   "metadata": {},
   "source": [
    "# Multiple hexagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591856f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ef554",
   "metadata": {},
   "outputs": [],
   "source": [
    " series = dataset[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e37a457",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = Ridge(alpha=0.1)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 48)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef0eb5",
   "metadata": {},
   "source": [
    "# lgb.LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5101ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = lgb.LGBMRegressor()\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157d025",
   "metadata": {},
   "source": [
    "# XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8990e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = XGBRegressor(objective='reg:squarederror', n_estimators=1000,tree_method='gpu_hist')\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    \n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Number : ',columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4aea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9951e3b",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = Ridge(alpha=0.4)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    \n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Number : ',columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549a06e",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47815da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast monthly births with random forest\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = RandomForestRegressor(max_depth=20, random_state=0)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    \n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Number : ',columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0716b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.iloc[0:100,0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b7c80",
   "metadata": {},
   "source": [
    "# HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99490fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = HuberRegressor()\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce1a85",
   "metadata": {},
   "source": [
    "# Lasso(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98586006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = Lasso(alpha = 0.1)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a3ea6f",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ea893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = Lasso(alpha = 4.0) # core\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450c117",
   "metadata": {},
   "source": [
    "# PassiveAggressiveRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d55b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = PassiveAggressiveRegressor() # core\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ac3df",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ad7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = ElasticNet() # core\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recursive multi-step forecast with linear algorithms\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5e127",
   "metadata": {},
   "source": [
    "# SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = SGDRegressor() # core\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = AdaBoostRegressor(n_estimators=1000) # core\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d94618",
   "metadata": {},
   "source": [
    "# RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=10, dropnan=True):\n",
    "\t#n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols = list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg.values\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test, :], data[-n_test:, :]\n",
    " \n",
    "# fit an xgboost model and make a one step prediction\n",
    "def xgboost_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = RANSACRegressor() # core\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict(asarray([testX]))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# split test row into input and output columns\n",
    "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
    "\t\t# fit model on history and make a prediction\n",
    "\t\tyhat = xgboost_forecast(history, testX)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "\t# estimate prediction error\n",
    "\terror = mean_absolute_error(test[:, -1], predictions)\n",
    "\treturn error, test[:, -1], predictions\n",
    " \n",
    "cols = list(dataset)\n",
    "\n",
    "for index in range(dataset.shape[1]):\n",
    "    columnSeriesObj = dataset.iloc[:, index]\n",
    "    #series = dataset[cols] #read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "# split dataset\n",
    "    V = columnSeriesObj.values #read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "    #values = series.values\n",
    "# transform the time series data into supervised learning\n",
    "    data = series_to_supervised(V, n_in=1)\n",
    "# evaluate\n",
    "    mae, y, yhat = walk_forward_validation(data, 24)\n",
    "    print('MAE: %.3f' % mae)\n",
    "# plot expected vs preducted\n",
    "    pyplot.plot(y, label='Expected')\n",
    "    pyplot.plot(yhat, label='Predicted')\n",
    "    print('Column Title : ', columnSeriesObj.name)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d91a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
