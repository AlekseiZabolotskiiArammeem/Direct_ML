{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b59a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "# Load all necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "#import torch\n",
    "\n",
    "import sys, getopt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "\n",
    "# forecast monthly births with xgboost\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "#from matplotlib import pyplot\n",
    "import pickle\n",
    "\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "import numpy as np; \n",
    "# Data manipulation\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "#from statsmodels.graphics.tsaplots import plot_acf\n",
    "#from statsmodels.graphics.tsaplots import plot_pacf\n",
    "#plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Modelado y Forecasting\n",
    "# ==============================================================================\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.cluster import OPTICS\n",
    "import pickle\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "#from pandarallel import pandarallel\n",
    "#pandarallel.initialize(progress_bar=True)\n",
    "from array import *\n",
    "import schedule\n",
    "import time\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "\n",
    "from h3 import h3\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    global ar\n",
    "    ar = []\n",
    "    global pred\n",
    "    pred = []\n",
    "    global datasetttt\n",
    "    connection = pg.connect(\"host=gw-sand-toyou.net.amhub.org dbname=amdelivery_sandbox user=a.zabolotskii password=r7LJ3WSR5PAYLYV3 sslmode=require\")\n",
    "    dataframedelivery = psql.read_sql('SELECT * FROM delivery_order LIMIT 20000', connection)\n",
    "\n",
    "    connection2 = pg.connect(\"host=gw-sand-toyou.net.amhub.org dbname=amdelivery_sandbox user=a.zabolotskii password=r7LJ3WSR5PAYLYV3 sslmode=require\")\n",
    "    dataframelocation = psql.read_sql('SELECT * FROM location  LIMIT 1000000', connection2)\n",
    "\n",
    "    merged_2 = dataframedelivery.merge(dataframelocation, how='inner', left_on=[\"pick_up_location\"], right_on=[\"id\"])\n",
    "    cols = ['lat','lon','creation_date']\n",
    "    data = merged_2[cols]\n",
    "    df2 = data\n",
    "    df2['creation_date'] = data['creation_date'].astype('datetime64[h]')\n",
    "    df2['orders'] = 1\n",
    "    df2= df2.groupby([\"lon\",\"lat\", \"creation_date\"], as_index=False)[\"orders\"].count()\n",
    "    df2 = df2.sort_values(by = ['creation_date'], ascending = [False])\n",
    "    h3_level = 9\n",
    " \n",
    "    def lat_lng_to_h3(row):\n",
    "        return h3.geo_to_h3(\n",
    "            row.lat, row.lon, h3_level)\n",
    " \n",
    "    orders = df2.apply(lat_lng_to_h3, axis=1)\n",
    "    df2['fid'] = orders\n",
    "    df2 = df2.rename(columns={\"creation_date\": \"time\"})\n",
    "    table = pd.pivot_table(df2, values='orders', index=['time'],columns=['fid'])\n",
    "    table = table.fillna(0)\n",
    "    table = table.sort_values(by = ['time'], ascending = [False])\n",
    "   \n",
    "    datasetttt = table[0:1100]\n",
    "    datasetttt = datasetttt.iloc[:,:10]\n",
    "    return datasetttt\n",
    "    \n",
    "def fitdata(datasetttt):\n",
    "    end_validation = 951\n",
    "    end_train = 800\n",
    "    for index in range(datasetttt.shape[1]):\n",
    "        columnSeriesObj = datasetttt.iloc[:, index]\n",
    "        columnSeriesObj = pd.Series(list(columnSeriesObj))\n",
    "        forecaster = ForecasterAutoregMultiOutput(\n",
    "                regressor = XGBRegressor(objective='reg:squarederror', n_estimators=1000),\n",
    "                lags = 20,\n",
    "                steps = 24\n",
    "                )\n",
    "\n",
    "    \n",
    "        columnSeriesObj1 = columnSeriesObj[48:1024]\n",
    "        columnSeriesObj2 = columnSeriesObj[24:1000]\n",
    "    #columnSeriesObj3 = columnSeriesObj[24:1000]\n",
    "        columnSeriesObj3 = columnSeriesObj[0:976]\n",
    "# Regressor's hyperparameters\n",
    "        param_grid = {'n_estimators': [100, 500],'max_depth': [4, 6]}\n",
    "# Lags used as predictors\n",
    "        lags_grid = [[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24], [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]]\n",
    "        results_grid = grid_search_forecaster(\n",
    "                        forecaster  = forecaster,\n",
    "                        y           = pd.Series(list(columnSeriesObj2)),#data[:,index],table11 = pd.Series(list(table1))   \n",
    "                        exog        = pd.Series(list(columnSeriesObj1)),#data[:,index],\n",
    "                        param_grid  = param_grid,\n",
    "                        lags_grid   = lags_grid,\n",
    "                        steps       = 24,\n",
    "                        metric      = 'mean_absolute_error',\n",
    "                        refit       = False,\n",
    "                        initial_train_size = 900,\n",
    "                        return_best = True,\n",
    "                        verbose     = False\n",
    "                  )\n",
    "        return forecaster\n",
    "        \n",
    "def predictions():\n",
    "    end_train = 800\n",
    "    end_validation = 951\n",
    "    for index in range(datasetttt.shape[1]):\n",
    "        columnSeriesObj = datasetttt.iloc[:, index]\n",
    "        columnSeriesObj = pd.Series(list(columnSeriesObj))\n",
    "        columnSeriesObj1 = columnSeriesObj[48:1024]\n",
    "        columnSeriesObj2 = columnSeriesObj[24:1000]\n",
    "    #columnSeriesObj3 = columnSeriesObj[24:1000]\n",
    "        columnSeriesObj3 = columnSeriesObj[0:976]\n",
    "        #forecaster = fitdata(datasetttt)\n",
    "        global forecaster\n",
    "        forecaster = ForecasterAutoregMultiOutput(\n",
    "                regressor = XGBRegressor(objective='reg:squarederror', n_estimators=1000),\n",
    "                lags = 20,\n",
    "                steps = 24\n",
    "                )\n",
    "        metric, predictions = backtesting_forecaster(\n",
    "                            forecaster = forecaster,\n",
    "                            y          = pd.Series(list(columnSeriesObj3)),\n",
    "                            exog       = pd.Series(list(columnSeriesObj2)),\n",
    "                            initial_train_size = len(columnSeriesObj[:end_validation]),\n",
    "                            steps      = 24,\n",
    "                            metric     = 'mean_absolute_error',\n",
    "                            refit      = False,\n",
    "                            verbose    = False)\n",
    "#for index in range(data.shape[1]):\n",
    "    #columnSeriesObj = data.iloc[:, index]\n",
    "    #columnSeriesObj = pd.Series(list(columnSeriesObj))                      \n",
    "        #fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        #columnSeriesObj.iloc[predictions.index].plot(linewidth=2, label='real', ax=ax)\n",
    "        #predictions.plot(linewidth=2, label='prediction', ax=ax)\n",
    "        #ax.set_title('Prediction vs real orders')\n",
    "        #ax.legend();\n",
    "        ar.append(predictions.copy())\n",
    "        print(ar)\n",
    "        \n",
    "#def DF():        \n",
    "#    arr = np.array(ar)\n",
    "#    arr = arr.reshape(25,10)\n",
    "#    arr = pd.DataFrame(arr,index=datasetttt[0:25].index,columns=datasetttt[0:10].columns )  \n",
    "#    print(arr)           \n",
    "        \n",
    "        \n",
    "def save_data():\n",
    "    \n",
    "    forecaster = fitdata(datasetttt)\n",
    "    PIK = \"models.pckl\"\n",
    "    pred.append(forecaster)\n",
    "    with open(\"models.pckl\", \"wb\") as f:\n",
    "        for forecaster in pred:\n",
    "             pickle.dump(forecaster, f)\n",
    "            \n",
    "    with open(PIK, \"rb\") as f:\n",
    "        print(pickle.load(f))\n",
    "\n",
    "    arr = np.array(ar)\n",
    "    arr = arr.reshape(25,10)\n",
    "    arr = pd.DataFrame(arr,index=datasetttt[0:25].index,columns=datasetttt[0:10].columns )     \n",
    "    print(arr)\n",
    "    save.to.file(filename='dd.csv')    \n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    #if torch.cuda.is_available():\n",
    "    #    dev = \"cuda:0\"\n",
    "        \n",
    "    #else:\n",
    "    #    dev = \"cpu\"\n",
    "     #   device = torch.device(dev)\n",
    "     #   torch.cuda.set_device(-1)\n",
    "        \n",
    "    schedule.every(24).hours.do(read_data)\n",
    "    datasetttt = read_data()      \n",
    "    schedule.every().monday.do(fitdata)  \n",
    "    fitdata(datasetttt)\n",
    "    schedule.every(24).hours.do(predictions) \n",
    "    predictions()\n",
    "    schedule.every(24).hours.do(save_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Program entry point.\n",
    "    \"\"\"\n",
    "    main(sys.argv[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
